var documenterSearchIndex = {"docs":
[{"location":"performance/sorting/#Model-sorting","page":"Model sorting","title":"Model sorting","text":"","category":"section"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"In RAM notation, the model implied covariance matrix is computed as","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"Sigma = F(I-A)^-1S(I-A)^-TF^T","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"If the model is acyclic, the observed and latent variables can be reordered such that (I-A) is lower triangular. This has the computational benefit that the inversion of lower triangular matrices can be carried out by specialized algorithms.","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"To automatically reorder your variables in a way that makes this optimization possible, we provide a sort! method that can be applied to ParameterTable objects to sort the observed and latent variables from the most exogenous ones to the most endogenous.","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"We use it as","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"sort!(parameter_table)\n\nmodel = Sem(\n    specification = parameter_table,\n    ...\n)","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"Models specified from sorted parameter tables will make use of the described optimizations.","category":"page"},{"location":"internals/internals/#Internals-and-Design","page":"Internals and design","title":"Internals and Design","text":"","category":"section"},{"location":"internals/internals/","page":"Internals and design","title":"Internals and design","text":"On the following pages, we document the internals and design of the package. Those informations are no prerequisite for extending the package (as decribed in the developer documentation)!, but they may be useful and hopefully interesting.","category":"page"},{"location":"developer/extending/#Extending-the-package","page":"Extending the package","title":"Extending the package","text":"","category":"section"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"As discussed in the section on Model construction, every Structural Equation Model (Sem) consists of four parts:","category":"page"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"image of Sem here -","category":"page"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"On the following pages, we will explain how you can define your own custom parts and \"plug them in\". There are certain things you have to do to define custom parts and some things you can do to have a more pleasent experience. In general, these requirements fall into the categories","category":"page"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"minimal (to use your custom part and fit a Sem with it)\nuse the outer constructor to build a model in a more convenient way\nuse additional functionality like standard errors, fit measures, etc.","category":"page"},{"location":"tutorials/first_model/#A-first-model","page":"A first model","title":"A first model","text":"","category":"section"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"In this tutorial, we will fit our very first Structural Equation Model with our package.  The example we are using is from the lavaan tutorial, so it may be familiar. It looks like this:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"(Image: Visualization of Political Democracy model)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"2022 © Yves Roseel","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We assume the StructuralEquationModels package is already installed. To use it in the current session, we run","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"using StructuralEquationModels","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We then first define the graph of our model in a syntax which is similar to the R-package lavaan:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"observed_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"observed_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We then use this graph to define a ParameterTable object","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"partable = ParameterTable(\n    latent_vars = latent_vars, \n    observed_vars = observed_vars, \n    graph = graph)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"load the example data","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"data = example_data(\"political_democracy\")","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"data = example_data(\"political_democracy\")","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"and specify our model as","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"model = Sem(\n    specification = partable,\n    data = data\n)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We can now fit the model via","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"model_fit = sem_fit(model)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"and compute fit measures as","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"fit_measures(model_fit)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We can also get a bit more information about the fitted model via the sem_summary() function:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"sem_summary(model_fit)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"To investigate the parameter estimates, we can update our partable object to contain the new estimates:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"update_estimate!(partable, model_fit)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"and investigate the solution with","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"sem_summary(partable)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"Congratulations, you fitted and inspected your very first model! To learn more about the different parts,  you may visit the sections on Model specification, Model construction, Model fitting and Model inspection.","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"If you want to learn how to extend the package (e.g., add a new loss function), you may visit the developer documentation (XXX).","category":"page"},{"location":"performance/starting_values/#Starting-values","page":"Starting values","title":"Starting values","text":"","category":"section"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"The sem_fit function has a keyword argument that takes either a vector of starting values or a function that takes a model as input to compute starting values. Current options are start_fabin3 for fabin 3 starting values (XXX) or start_simple for simple starting values. Additional keyword arguments to sem_fit are passed to the starting value function. For example,","category":"page"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"    sem_fit(\n        model; \n        start_val = start_simple,\n        start_covariances_latent = 0.5\n    )","category":"page"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"uses simple starting values with 0.5 as a starting value for covariances between latent variables.","category":"page"},{"location":"tutorials/specification/parameter_table/#ParameterTable-interface","page":"ParameterTable interface","title":"ParameterTable interface","text":"","category":"section"},{"location":"performance/symbolic/#Symbolic-precomputation","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"","category":"section"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"In RAM notation, the model implied covariance matrix is computed as","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"Sigma = F(I-A)^-1S(I-A)^-TF^T","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"If the model is acyclic, we can compute","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"(I-A)^-1 = sum_k = 0^n A^k","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"for some n  infty. Typically, the S and A matrices are sparse. In our package, we offer symbolic precomputation of Sigma, nablaSigma and even nabla^2Sigma for acyclic models to optimally exploit this sparsity. To use this feature, simply use the RAMSymbolic imply type for your model.","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"This can decrase model fitting time, but will also increase model building time (as we have to carry out the symbolic computations and compile specialised functions). As a result, this is probably not beneficial to use if you only fit a single model, but can lead to great improvements if you fit the same modle to multiple datasets (e.g. to compute bootstrap standard errors).","category":"page"},{"location":"tutorials/specification/ram_matrices/#RAMMatrices-interface","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"","category":"section"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Models can also be specified by an object of type RAMMatrices.  The RAM (reticular action model) specification corresponds to three matrices; the A matrix containing all directed parameters, the S matrix containing all undirected parameters, and the F matrix filtering out latent variables from the model implied covariance.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"The model implied covariance matrix for the observed variables of a SEM is then computed as","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Sigma = F(I-A)^-1S(I-A)^-TF^T","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"For A first model, the corresponding specification looks like this:","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"\n\nS =[:θ1   0    0     0     0      0     0     0     0     0     0     0     0     0\n    0     :θ2  0     0     0      0     0     0     0     0     0     0     0     0\n    0     0     :θ3  0     0      0     0     0     0     0     0     0     0     0\n    0     0     0     :θ4  0      0     0     :θ15  0     0     0     0     0     0\n    0     0     0     0     :θ5   0     :θ16  0     :θ17  0     0     0     0     0\n    0     0     0     0     0     :θ6  0      0     0     :θ18  0     0     0     0\n    0     0     0     0     :θ16  0     :θ7   0     0     0     :θ19  0     0     0\n    0     0     0     :θ15 0      0     0     :θ8   0     0     0     0     0     0\n    0     0     0     0     :θ17  0     0     0     :θ9   0     :θ20  0     0     0\n    0     0     0     0     0     :θ18 0      0     0     :θ10  0     0     0     0\n    0     0     0     0     0     0     :θ19  0     :θ20  0     :θ11  0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     :θ12  0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     :θ13  0\n    0     0     0     0     0     0     0     0     0     0     0     0     0     :θ14]\n\nF =[1.0 0 0 0 0 0 0 0 0 0 0 0 0 0\n    0 1 0 0 0 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0 0 0 0 0\n    0 0 0 0 0 1 0 0 0 0 0 0 0 0\n    0 0 0 0 0 0 1 0 0 0 0 0 0 0\n    0 0 0 0 0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 0 0 0 0 1 0 0 0 0 0\n    0 0 0 0 0 0 0 0 0 1 0 0 0 0\n    0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n\nA =[0  0  0  0  0  0  0  0  0  0  0     1.0   0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ21  0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ22  0     0\n    0  0  0  0  0  0  0  0  0  0  0     0     1.0   0\n    0  0  0  0  0  0  0  0  0  0  0     0     :θ23  0\n    0  0  0  0  0  0  0  0  0  0  0     0     :θ24  0\n    0  0  0  0  0  0  0  0  0  0  0     0     :θ25  0\n    0  0  0  0  0  0  0  0  0  0  0     0     0     1\n    0  0  0  0  0  0  0  0  0  0  0     0     0     :θ26\n    0  0  0  0  0  0  0  0  0  0  0     0     0     :θ27\n    0  0  0  0  0  0  0  0  0  0  0     0     0     :θ28\n    0  0  0  0  0  0  0  0  0  0  0     0     0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ29  0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ30  :θ31  0]\n\nθ = Symbol.(:θ, 1:31)\n\nspec = RAMMatrices(;\n    A = A, \n    S = S, \n    F = F, \n    parameters = θ,\n    colnames = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8, :ind60, :dem60, :dem65]\n)\n\nmodel = Sem(\n    specification = spec,\n    ...\n)","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Let's have a look at what to do step by step:","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"First, we specify the A, S and F-Matrices.  For a free parameter, we write a Symbol like :θ1 (or any other symbol we like) to the corresponding place in the respective matrix, the constrain parameters to be equal we just use the same Symbol in the respective entries.  To fix a parameter (as in the A-Matrix above), we just write down the number we want to fix it to.  All other entries are 0.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Second, we specify a vector of symbols containing our parameters.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Third, we construct an object of type RAMMatrices, and pass our matrices and parameters, as well as the column names of our matrices to it.  Those are quite important, as they will be used to rearrange your data to match it to your RAMMatrices specification.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Finally, we construct a model, passing our RAMMatrices as the specification = ... argument.","category":"page"},{"location":"tutorials/specification/ram_matrices/#Meanstructure","page":"RAMMatrices interface","title":"Meanstructure","text":"","category":"section"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"According to the RAM, model implied mean values of the observed variables are computed as","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"mu = F(I-A)^-1M","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"where M is a vector of mean parameters. To estimate the means of the observed variables in our example (and set the latent means to 0), we would specify the model just as before but add ","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"...\n\nM = [:x32; :x33; :x34; :x35; :x36; :x37; :x38; :x39; :x40; :x41; :x42; 0; 0; 0]\n\nθ = Symbol.(:θ, 1:42)\n\nspec = RAMMatrices(;\n    ...,\n    M = M)\n\n...\n","category":"page"},{"location":"tutorials/specification/ram_matrices/#Convert-from-and-to-ParameterTables","page":"RAMMatrices interface","title":"Convert from and to ParameterTables","text":"","category":"section"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"To convert a RAMMatrices object (let's keep the name spec from above) to a ParameterTable, simply use partable = ParameterTable(spec).  To convert an object of type ParameterTable to RAMMatrices, you can use ram_matrices = RAMMatrices(partable).","category":"page"},{"location":"internals/files/#Files","page":"files","title":"Files","text":"","category":"section"},{"location":"internals/files/","page":"files","title":"files","text":"We briefly describe the file and folder structure of the package.","category":"page"},{"location":"internals/files/#Source-code","page":"files","title":"Source code","text":"","category":"section"},{"location":"internals/files/","page":"files","title":"files","text":"All source code is in the \"src\" folder:","category":"page"},{"location":"internals/files/","page":"files","title":"files","text":"\"src\"","category":"page"},{"location":"internals/files/","page":"files","title":"files","text":"\"StructuralEquationModels.jl\" defines the module and the exported objects\n\"types.jl\" defines all abstract types and the basic type hierarchy\n\"objective_gradient_hessian.jl\" contains methods for computing objective, gradient and hessian values for different model types as well as generic fallback methods\nThe four folders \"observed\", \"imply\", \"loss\" and \"diff\" contain implementations of specific subtypes (for example, the \"loss\" folder contains a file \"ML.jl\" that implements the SemML loss function).\n\"optimizer\" contains connections to different optimization backends (aka methods for sem_fit)\n\"optim.jl\": connection to the Optim.jl package\n\"NLopt.jl\": connection to the NLopt.jl package\n\"frontend\" contains user-facing functions\n\"specification\" contains functionality for model specification\n\"fit\" contains functionality for model assessment, like fit measures and standard errors\n\"additional_functions\" contains helper functions for simulations, loading artifacts (example data) and various other things","category":"page"},{"location":"internals/files/#Tests-and-Documentation","page":"files","title":"Tests and Documentation","text":"","category":"section"},{"location":"internals/files/","page":"files","title":"files","text":"Tests are in the \"test\" folder, documentation in the \"docs\" folder.","category":"page"},{"location":"tutorials/specification/specification/#Model-specification","page":"Model specification","title":"Model specification","text":"","category":"section"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"We provide different interfaces for specifying a model: the Graph interface, the ParameterTable interface, and the RAMMatrices interface. These different specification objects can be (and are internally) converted to each other; but not every conversion is possible - see this picture:","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"imagine flowchart here -","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"In general (and especially if you come from lavaan), it is the easiest to follow the steps from the page A first model, that is specify a graph object, convert it to a prameter table, and use this parameter table to construct your models:","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"observed_vars = ...\nlatent_vars   = ...\n\ngraph = @StenoGraph begin\n    ...\nend\n\npartable = ParameterTable(\n    latent_vars = latent_vars, \n    observed_vars = observed_vars, \n    graph = graph)\n\nmodel = Sem(\n    specification = partable,\n    ...\n)","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"If you have an OpenMx background, and are familiar with their way of specifying structural equation models via RAM matrices, the RAMMatrices interface may be of interest for you.","category":"page"},{"location":"developer/loss/#Custom-loss-functions","page":"Custom loss functions","title":"Custom loss functions","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"As an example, we will implement ridge regularization. Maximum likelihood estimation with ridge regularization consists of optimizing the objective","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"F_ML(theta) + alpha lVert theta_I rVert^2_2","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Since we allow for the optimization of sums of loss functions, and the maximum likelihood loss function already exists, we only need to implement the ridge part (and additionally get ridge regularization for WLS and FIML estimation for free).","category":"page"},{"location":"developer/loss/#Minimal","page":"Custom loss functions","title":"Minimal","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To define a new loss function, you have to define a new type that is a subtype of SemLossFunction:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"struct Ridge <: SemLossFunction\n    α\n    I\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"We store the hyperparameter α and the indices I of the parameters we want to regularize.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Additionaly, we need to define a method to compute the objective:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"import StructuralEquationModels: objective!\n\nobjective!(ridge::Ridge, par, model::AbstractSemSingle) = ridge.α*sum(par[ridge.I].^2)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"That's all we need to make it work! For example, we can now fit A first model with ridge regularization:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"We first give som eparameters labels to be able to identify as targets for the regularization:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"graph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → label(:a)*dem60\n    dem60 → label(:b)*dem65\n    ind60 → label(:c)*dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend\n\npartable = ParameterTable(\n    latent_vars = latent_vars,\n    observed_vars = observed_vars,\n    graph = graph)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"parameter_indices  = get_identifier_indices([:a, :b, :c], partable)\nmyridge = Ridge(0.01, parameter_indices)\n\nmodel = SemFiniteDiff(\n    specification = partable,\n    data = data,\n    loss = (SemML, myridge)\n)\n\nmodel_fit = sem_fit(model)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"This is one way of specifying the model - we now have one model with multiple loss functions. Because we did not provide a gradient for Ridge, we have to specify a SemFiniteDiff model that computes numerical gradients with finite difference approximation.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Note that the last argument to the objective! method is the whole model. Therefore, we can access everything that is stored inside our model everytime we compute the objective value for our loss function. Since ridge regularization is a very easy case, we do not need to do this. But maximum likelihood estimation for example depens on both the observed and the model implied covariance matrix. See Second example - maximum likelihood for information on how to do that.","category":"page"},{"location":"developer/loss/#Improve-performance","page":"Custom loss functions","title":"Improve performance","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"By far the biggest improvements in performance will result from specifying analytical gradients. We can do this for our example:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"import StructuralEquationModels: gradient!\n\nfunction gradient!(ridge::Ridge, par, model::AbstractSemSingle)\n    gradient = zero(par)\n    gradient[ridge.I] .= 2*ridge.α*par[ridge.I]\n    return gradient\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Now, instead of specifying a SemFiniteDiff, we can use the normal Sem constructor:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"model_new = Sem(\n    specification = partable,\n    data = data,\n    loss = (SemML, myridge)\n)\n\nmodel_fit = sem_fit(model_new)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"The results are thew same, but we can verify that the computational costs are way lower (for this, the julia package BenchmarkTools has to be installed):","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"using BenchmarkTools\n\n@benchmark sem_fit(model)\n\n@benchmark sem_fit(model_new)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"The exact results of those benchmarks are of course highly depended an your system (processor, RAM, etc.), but you should see that the median computation time with analytical gradients drops to about 5% of the computation without analytical gradients.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Additionally, you may provide analytic hessians by writing a method of the form","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function hessian!(ridge::Ridge, par, model::AbstractSemSingle)\n    ...\n    return hessian\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"however, this will only matter if you use an optimization algorithm that makes use of the hessians. Our gefault algorithmn LBFGS from the package Optim.jl does not use hessians (for example, the Newton algorithmn from the same package does).","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Do improve performance even more, you can write a method of the form","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function objective_gradient!(ridge::Ridge, par, model::AbstractSemSingle)\n    ...\n    return objective, gradient\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"This is beneficial when the computation of the objective and gradient share common computations. For example, in maximum likelihood estimation, the model implied covariance matrix has to be inverted to both compute the objective and gradient. Whenever the optimization algorithmn asks for the objective value and gradient at the same point, we call objective_gradient! and only have to do the shared computations - in this case the matric inversion - once.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"If you want to do hessian-based optimization, there are also the following methods:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function objective_hessian!(ridge::Ridge, par, model::AbstractSemSingle)\n    ...\n    return objective, hessian\nend\n\nfunction gradient_hessian!(ridge::Ridge, par, model::AbstractSemSingle)\n    ...\n    return gradient, hessian\nend\n\nfunction objective_gradient_hessian!(ridge::Ridge, par, model::AbstractSemSingle)\n    ...\n    return objective, gradient, hessian\nend","category":"page"},{"location":"developer/loss/#Convenient","page":"Custom loss functions","title":"Convenient","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To be able to build the model with the Outer Constructor, you need to add a constructor for your loss function that only takes keyword arguments and allows for passing optional additional kewyword arguments. A constructor is just a function that creates a new instance of your type:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function MyLoss(;arg1 = ..., arg2, kwargs...)\n    ...\n    return MyLoss(...)\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"All keyword arguments that a user passes to the Sem constructor are passed to your loss function. In addition, all previously constructed parts of the model (imply and observed part) are passed as keyword arguments as well as the number of parameters n_par = ..., so your constructor may depend on those. For example, the constructor for SemML in our package depends on the additional argument meanstructure as well as the observed part of the model to pre-allocated arrays of the same size as the observed covariance matrix and the observed mean vector: ","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function SemML(;observed, meanstructure = false, approx_H = false, kwargs...)\n    isnothing(obs_mean(observed)) ?\n        meandiff = nothing :\n        meandiff = copy(obs_mean(observed))\n    return SemML(\n        similar(obs_cov(observed)),\n        similar(obs_cov(observed)),\n        meandiff,\n        approx_H,\n        Val(meanstructure)\n        )\nend","category":"page"},{"location":"developer/loss/#Additional-functionality","page":"Custom loss functions","title":"Additional functionality","text":"","category":"section"},{"location":"developer/loss/#Update-observed-data","page":"Custom loss functions","title":"Update observed data","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"If you are planing a simulation study where you have to fit the same model to many different datasets, it is computationally beneficial to not build the whole model completely new everytime you change your data. Therefore, we provide a function to update the data of your model, swap_observed(model(semfit); data = new_data). However, we can not now beforehand in what way your loss function depends on the specific datasets. The solution is to provide a method for update_observed. Since Ridge does not depend on the data at all, this is quite easy:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"import StructuralEquationModels: update_observed\n\nupdate_observed(ridge::Ridge, observed::SemObs; kwargs...) = ridge","category":"page"},{"location":"developer/loss/#Access-additional-information","page":"Custom loss functions","title":"Access additional information","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"If you want to provide a way to query information about loss functions of your type, you can provide functions for that:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"hyperparameter(ridge::Ridge) = ridge.α\nregularization_indices(ridge::Ridge) = ridge.I","category":"page"},{"location":"developer/loss/#Second-example-maximum-likelihood","page":"Custom loss functions","title":"Second example - maximum likelihood","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Let's make a sligtly more complicated example: we will reimplement maximum likelihood estimation.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To keep it simple, we only cover models without a meanstructure. The maximum likelihood objective is defined as","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"F_ML = log det Sigma_i + mathrmtr(Sigma_i Sigma_o)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"where Sigma_i is the model implied covariance matrix and Sigma_o is the observed covariance matrix. We can query the model implied covariance matrix from the imply par of our model, and the observed covariance matrix from the observed path of our model.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To get information on what we can access from a certain imply or observed type, we can look in it`s documentation an the pages XXX or via the help mode of the REPL:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"julia>?\n\nhelp?> RAM\n\nhelp?> SemObsCommon","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"We see that the model implied covariance matrix can be assessed as Σ(imply) and the observed covariance matrix as obs_cov(observed).","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"With this information, we write can implement maximum likelihood optimization as","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"struct MaximumLikelihood <: SemLossFunction end\n\nusing LinearAlgebra\nimport StructuralEquationModels: Σ, obs_cov, objective!\n\nfunction objective!(semml::MaximumLikelihood, parameters, model::AbstractSem)\n    # access the model implied and observed covariance matrices\n    Σᵢ = Σ(imply(model))\n    Σₒ = obs_cov(observed(model))\n    # compute the objective\n    if isposdef(Σᵢ) # is the model implied covariance matrix positive definite?\n        return logdet(Σᵢ) + tr(inv(Σᵢ)*Σₒ)\n    else\n        return Inf\n    end\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"to deal with eventual non-positive definiteness of the model implied covariance matrix, we chose the pragmatic way of returning Infinity whenever this is the case.","category":"page"},{"location":"developer/observed/#Custom-observed-types","page":"Custom observed types","title":"Custom observed types","text":"","category":"section"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"The implementation of new observed types is very similar to loss functions, so we will just go over it briefly (for additional information, revisit Custom loss functions).","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"First, we need to define a new struct that is a subtype of SemObs:","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"struct MyObserved <: SemObs\n    ...\nend","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"Additionally, we can write an outer constructor that will typically depend on the keyword argument data = ...:","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"function MyObserved(;data, kwargs...)\n    ...\n    return MyObserved(...)\nend","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"To compute some fit indices, you need to provide methods for","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"# Number of observed datapoints\nn_obs(observed::MyObserved) = ...\n# Number of manifest variables\nn_man(observed::MyObserved) = ...","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"As always, you can add additional methods for properties that imply types and loss function want to access, for example (from the SemObsCommon implementation):","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"obs_cov(observed::SemObsCommon) = observed.obs_cov","category":"page"},{"location":"tutorials/collection/collection/#Collections","page":"Collections","title":"Collections","text":"","category":"section"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"With StructuralEquationModels.jl, you can fit weighted sums of structural equation models.  The most common use case for this are Multigroup models.  Another use case may be optimizing the sum of loss functions for some of which you do know the analytic gradient, but not for others.  In this case, you can optimize the sum of a Sem and a SemFiniteDiff (or any other differentiation method).","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"To use this feature, you have to construct a SemEnsemble model, which is actually quite easy:","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"# models\nmodel_1 = Sem(...)\n\nmodel_2 = SemFiniteDiff(...)\n\nmodel_3 = SemForwardDiff(...)\n\nmodel_ensemble = SemEnsemble(model_1, model_2, model_3; diff = ...)","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"So you just construct the individual models (however you like) and pass them to SemEnsemble. One important thing to note is that the individual diff entries of each model do not matter (as you can optimize your ensemble model only with one algorithmn from one optimization suite). Instead, SemEnsemble has its own diff part that specifies the backend for the whole ensemble model. You may also pass a vector of weigths to SemEnsemble. By default, those are set to N_modelN_total, i.e. each model is weighted by the number of observations in it's data (which matches the formula for multigroup models).","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"Multigroup models can also be specified via the graph interface; for an example, see Multigroup models.","category":"page"},{"location":"developer/imply/#Custom-imply-types","page":"Custom imply types","title":"Custom imply types","text":"","category":"section"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"We recommend to read first the part Custom loss functions, as the overall implementation is the same and we will describe it here more briefly.","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"Imply types are of subtype SemImply. To implement your own imply type, you should define a struct","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"struct MyImply <: SemImply\n    ...\nend","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"and at least a method to compute the objective","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"import StructuralEquationModels: objective!\n\nfunction objective!(imply::MyImply, par, model::AbstractSemSingle)\n    ...\n    return nothing\nend","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"This method should compute and store things you want to make available to the loss functions, and returns nothing. For example, as we have seen in Second example - maximum likelihood, the RAM imply type computes the model-implied covariance matrix and makes it available via Σ(imply). To make stored computations available to loss functions, simply write a function - for example, for the RAM imply type we defined","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"Σ(imply::RAM) = imply.Σ","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"Additionally, you can specify methods for gradient and hessian as well as the combinations describen in Custom loss functions.","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"The last thing nedded to make it work is a method for n_par that takes your imply type and returns the number of parameters of the model:","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"n_par(imply::MyImply) = ...","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"Just as described in Custom loss functions, you may define a constructor. Typically, this will depend on the specification = ... argument that can be a ParameterTable or a RAMMatrices object.","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"We implement an ImplyEmpty type in our package that does nothing but serving as an imply field in case you are using a loss function that does not need any imply type at all. You may use it as a template for defining your own imply type, as it also shows how to handle the specification objects.","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"############################################################################\n### Types\n############################################################################\n\nstruct ImplyEmpty{V, V2} <: SemImply\n    identifier::V2\n    n_par::V\nend\n\n############################################################################\n### Constructors\n############################################################################\n\nfunction ImplyEmpty(;\n        specification,\n        kwargs...)\n\n        ram_matrices = RAMMatrices(specification)\n        identifier = StructuralEquationModels.identifier(ram_matrices)\n\n        n_par = length(ram_matrices.parameters)\n\n        return ImplyEmpty(identifier, n_par)\nend\n\n############################################################################\n### methods\n############################################################################\n\nobjective!(imply::ImplyEmpty, par, model) = nothing\ngradient!(imply::ImplyEmpty, par, model) = nothing\nhessian!(imply::ImplyEmpty, par, model) = nothing\n\n############################################################################\n### Recommended methods\n############################################################################\n\nidentifier(imply::ImplyEmpty) = imply.identifier\nn_par(imply::ImplyEmpty) = imply.n_par\n\nupdate_observed(imply::ImplyEmpty, observed::SemObs; kwargs...) = imply","category":"page"},{"location":"developer/imply/","page":"Custom imply types","title":"Custom imply types","text":"As you see, similar to Custom loss functions we implement a method for update_observed. Additionally, you should store the identifier from the specification object and write a method for identifier, as this will make it possible to access parameter indices by label.","category":"page"},{"location":"tutorials/construction/construction/#Model-construction","page":"Model construction","title":"Model construction","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"There are two different ways of specifying a SEM in our package. You can use the Outer Constructor oder Build by parts.  All tutorials until now used the outer constructor Sem(specification = ..., data = ..., ...), which is normally the more convenient way. However, our package is build for extensibility, so there may be cases where user-defined parts of a model do not work with the outer constructor. Therefore, building the model by parts is always available as a fallback.","category":"page"},{"location":"tutorials/construction/construction/#What-is-a-Structural-Equation-Model?","page":"Model construction","title":"What is a Structural Equation Model?","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"In our package, every Structural Equation Model (Sem) consists of four parts:","category":"page"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"image of Sem here -","category":"page"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"Every part has different subtypes that can serve in the respective place. Those parts are interchangable like Legos (we will make a few examples at the end).","category":"page"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"The difference in both contruction methods (building by parts or with the outer constructor) is only about how to arrive at the final model; the choice about which 'Legos' to put together is independet from it. However, the outer constructor simply has some default values that are put in place unless you demand something else.","category":"page"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"The rest of this page is about which 'Legos' are available for each part. The specific pages Outer Constructor and Build by parts are about how to stick them together to a final model.","category":"page"},{"location":"tutorials/construction/construction/#observed","page":"Model construction","title":"observed","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"The observed part contains all necessary information about the observed data; for example the observed covariance matrix. Currently, we have two options: SemObsCommon and SemObsMissing.  As the names suggest, you want to use SemObsMissing if your data contains missing values, and SemObsCommon otherwise.","category":"page"},{"location":"tutorials/construction/construction/#imply","page":"Model construction","title":"imply","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"The imply part is what your model implies about the data, for example, the model-implied covariance matrix.  There are two options at the moment: RAM, which uses the RAM to compute the model implied covariance matrix, and RAMSymbolic which only differes from the RAM type in that it symbolically pre-computes part of the model, which increases subsequent performance in model fitting (see Symbolic precomputation).","category":"page"},{"location":"tutorials/construction/construction/#loss","page":"Model construction","title":"loss","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"The loss part specifies the objective function (or loss function) that is optimized to find the parameter estimates. If it contains more then one loss function, we find the parameters by minimizing the sum of loss functions (for example in maximum likelihood estimation + ridge regularization). Available loss functions are","category":"page"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"SemML: maximum likelihood estimation\nSemWLS: weighted leat squares estimation\nSemFIML: full-information maximum likelihood estimation\nSemRidge: ridge regularization","category":"page"},{"location":"tutorials/construction/construction/#diff","page":"Model construction","title":"diff","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"The diff part of a model connects to the numerical optimization backend used to fit the model. It can be used to control options like the optimization algorithm, linesearch, stopping criteria, etc. There are currently two available backends, SemDiffOptim connecting to the Optim.jl backend, and SemDiffNLopt connecting to the NLopt.jl backend.","category":"page"},{"location":"tutorials/construction/construction/#API","page":"Model construction","title":"API","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model construction","title":"Model construction","text":"SemObsCommon","category":"page"},{"location":"tutorials/construction/construction/#StructuralEquationModels.SemObsCommon","page":"Model construction","title":"StructuralEquationModels.SemObsCommon","text":"More here soon.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/specification/graph_interface/#Graph-interface","page":"Graph interface","title":"Graph interface","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/#Workflow","page":"Graph interface","title":"Workflow","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"As discussed before, when using the graph interface, you can specify your model as a graph","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"graph = @StenoGraph begin\n    ...\nend","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"and convert it to a ParameterTable to construct your models:","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"observed_vars = ...\nlatent_vars   = ...\n\npartable = ParameterTable(\n    latent_vars = latent_vars, \n    observed_vars = observed_vars, \n    graph = graph)\n\nmodel = Sem(\n    specification = partable,\n    ...\n)","category":"page"},{"location":"tutorials/specification/graph_interface/#Parameters","page":"Graph interface","title":"Parameters","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"In general, there are two different types of parameters: directed and indirected parameters. A directed parameter from the variable x to y can be specified as x → y (or equivalently as y ← x); an undirected parameter as x ↔ y. We allow multiple variables on both sides of an arrow, for example x → [y z] or [a b] → [c d]. The later specifies element wise edges; that is its the same as a → c; b → d. If you want edges corresponding to the cross-product, we have the double lined arrow [a b] ⇒ [c d], corresponding to a → c; a → d; b → c; b → d. The undirected arrows ↔ (element-wise) and ⇔ (crossproduct) behave the same way.","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"note: Unicode symbols in julia\nThe → symbol is a unicode symbol allowed in julia (among many others; see this list). You can enter it in the julia REPL or the vscode IDE by typing \\to followed by hitting tab. Similarly, ← = \\leftarrow,\n↔ = \\leftrightarrow,\n⇒ = \\Rightarrow,\n⇐ = \\Leftarrow,\n⇔ = \\LeftrightarrowThis may seem cumbersome at first, but with some practice allows you to specify your models in a really elegant way: [x₁ x₂ x₃] ← ξ → η → [y₁ y₂ y₃].","category":"page"},{"location":"tutorials/specification/graph_interface/#Options","page":"Graph interface","title":"Options","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The graph syntax allows you to fix parameters to specific values, label them, and encode equality constraints by giving different parameters the same label. The following syntax example","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"graph = @StenoGraph begin\n\n    ξ₁ → fixed(1.0)*x1 + x2 + label(:a)*x3\n    ξ₂ → fixed(1.0)*x4 + x5 + label(:λ₁)*x6\n    ξ₃ → fixed(NaN)*x7 + x8 + label(:λ₁)*x9\n\n    ξ₃ ↔ fixed(1.0)*ξ₃\n    ...\n\nend","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"would ","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"fix the directed effects from ξ₁ to x1 and from ξ₂ to x2 to 1\nleave the directed effect from ξ₃ to x3 free but instead restrict the variance of ξ₃ to 1\ngive the effect from ξ₁ to x3 the label :a (which can be convenient later if you want to retrieve information from your model about that specific parameter)\nconstrain the effect from ξ₂ to x6 and ξ₃ to x9 to be equal as they are both labeled the same.","category":"page"},{"location":"tutorials/specification/graph_interface/#Using-variables-inside-the-graph-specification","page":"Graph interface","title":"Using variables inside the graph specification","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"As you saw above and in the A first model example, the graph object needs to be converted to a parameter table:","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"partable = ParameterTable(\n    latent_vars = latent_vars, \n    observed_vars = observed_vars, \n    graph = graph)","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The ParameterTable constructor also needs you to specify a vector of observed and latent variables, in the example above this would correspond to","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"observed_vars = [:x1 :x2 :x3 :x4 :x5 :x6 :x7 :x8 :x9]\nlatent_vars   = [:ξ₁ :ξ₂ :ξ₃]","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The variable names (:x1) have to be symbols, the syntax :something creates an object of type Symbol. But you can also use vectors of symbols inside the graph specification, escaping them with _(...). For example, this graph specification","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"@StenoGraph begin\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ⇔ _(latent_vars)\nend","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"creates undirected effects coresponding to ","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"the variances of all observed variables and\nthe variances plus covariances of all latent variables","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"So if you want to work with a subset of variables, simply specify a vector of symbols somevars = [...], and inside the graph specification, refer to them as _(somevars).","category":"page"},{"location":"tutorials/specification/graph_interface/#Meanstructure","page":"Graph interface","title":"Meanstructure","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"Mean parameters are specified as a directed effect from 1 to the respective variable. In our example above, to estimate a mean parameter for all observed variables, we may write","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"@StenoGraph begin\n    Symbol(\"1\") → _(observed_vars)\nend","category":"page"},{"location":"tutorials/specification/graph_interface/#Further-Reading","page":"Graph interface","title":"Further Reading","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/#What's-this-strange-looking-@-thing?","page":"Graph interface","title":"What's this strange looking @-thing?","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The syntax to specify graphs (@StenoGraph) may seem a bit strange if you are not familiar with the julia language. It is called a macro, but explaining this concept in detail is beyond this documentation (and not necessary to understand to specify models). However, if you want to know more about it, you may have a look at the respective part of the manual.","category":"page"},{"location":"tutorials/specification/graph_interface/#The-StenoGraphs-Package","page":"Graph interface","title":"The StenoGraphs Package","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"Behind the scenes, we are using the StenoGraphs package to specify our graphs. It makes a domain specific language available that allows you to specify graphs with arbitrary information attached to its edges and nodes (for structural equation models, this may be the name or the value of a parameter). Is also allows you to specify your own types to \"attach\" to the graph, called a Modifier. So if you contemplate about writing your own modifier (e.g., to mark a variable as ordinal, an effect as quadratic, ...), please refer to the StenoGraphs documentation.","category":"page"},{"location":"tutorials/construction/build_by_parts/#Build-by-parts","page":"Build by parts","title":"Build by parts","text":"","category":"section"},{"location":"tutorials/construction/outer_constructor/#Outer-Constructor","page":"Outer Constructor","title":"Outer Constructor","text":"","category":"section"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"We already have seen the outer constructor in action in A first model:","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data\n)\n\n# output\n\nStructural Equation Model\n- Loss Functions\n   SemML\n- Fields\n   observed:  SemObsCommon\n   imply:     RAM\n   diff:      SemDiffOptim","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"The output of this call tells you exactly what model you just constructed (i.e. what the loss functions, observed, imply and diff parts are).","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"As you can see, by default, we use maximum likelihood estimation, the RAM imply type and the Optim.jl optimization backend.  To choose something different, you can provide it as a keyword argument:","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data,\n    observed = ...,\n    imply = ...,\n    loss = ...,\n    diff = ...\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"For example, to construct a model for weighted least squares estimation that uses symbolic precomputation and the NLopt backend, write","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data,\n    imply = RAMSymbolic,\n    loss = SemWLS,\n    diff = SemDiffNLopt\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"In the section on Model construction, we go over the different options you have for each part of the model. Let's make another example: to use full information maximum likelihood information (FIML), write","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data,\n    loss = SemFIML,\n    observed = SemObsMissing\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"You may also provide addition arguments for specific parts of the model. For example, WLS estimation uses per default","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"W = frac12 D^T(S^-1otimes S^-1)D","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"as the weight matrix, where D is the so-called duplication matrix and S is the observed covariance matrix. However, you can pass any other weight matrix you want (to achieve UWL, DWLS, ADF estimation, for example) as a keyword argument:","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"W = ...\n\nmodel = Sem(\n    specification = partable,\n    data = data,\n    imply = RAMSymbolic,\n    loss = SemWLS\n    wls_weight_matrix = W\n)\n","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"To see what additional keyword arguments are supported, you can consult the documentation of the specific part of the model (by either using help(...), or typing ? in the REPL to enter the help mode and then typing the name of the thing you want to know something about):","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"help(SemWLS)\n\n# output\n\nOUTPUT MISSING!\n","category":"page"},{"location":"tutorials/construction/outer_constructor/#Optimize-loss-functions-without-implemented-analytic-gradient","page":"Outer Constructor","title":"Optimize loss functions without implemented analytic gradient","text":"","category":"section"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"For loss functions without analytic gradients, it is possible to use finite difference approximation or forward mode automatic differentiation.  All loss functions provided in the package do have analytic gradients (and some even hessians or approximations thereof), so there is no need do use this feature if you are only working with them. However, if you implement your own loss function, you do not have to provide analytic gradients. In that case, you may construct your model just as before, but swap the Sem constructor for either SemFiniteDiff or SemForwardDiff. For example","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = SemFiniteDiff(\n    specification = partable,\n    data = data\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"constructs a model that will use finite difference approximation if you estimate the parameters via sem_fit(model). Both SemFiniteDiff and SemForwardDiff have an additional keyword argument, has_gradient = ... that can be set to true to indicate that the model has analytic gradients, and only the hessian should be computed via finite difference approximation / automatic differentiation. For example","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"using Optim, LineSearches\n\nmodel = SemFiniteDiff(\n    specification = partable,\n    data = data,\n    has_gradient = true,\n    algorithm = Newton()\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"will construct a model that, when fitted, will use Newton's Method from the Optim.jl package with analytic gradients and hessians computed via finite difference approximation.","category":"page"},{"location":"performance/mixed_differentiation/#Mixed-analytical-and-automatic-differentiation","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"","category":"section"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"This way of specifying our model is not ideal, however, because now also the maximum likelihood loss function lives inside a SemFiniteDiff model, and this means even though we have defined analytical gradients for it, we do not make use of them.","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"A more efficient way is therefore to specify our model as an ensemble model: ","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"model_ml = Sem(\n    specification = partable,\n    data = data,\n    loss = SemML\n)\n\nmodel_ridge = SemFiniteDiff(\n    specification = partable,\n    data = data,\n    loss = myridge\n)\n\nmodel_ml_ridge = SemEnsemble(model_ml, model_ridge)\n\nmodel_ml_ridge_fit = sem_fit(model_ml_ridge)","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"The results of both methods will be the same, but we can verify that the computation costs differ (the package BenchmarkTools has to be installed for this):","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"using BenchmarkTools\n\n@benchmark sem_fit(model)\n\n@benchmark sem_fit(model_ml_ridge)","category":"page"},{"location":"tutorials/inspection/inspection/#Model-inspection","page":"Model inspection","title":"Model inspection","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"using StructuralEquationModels \n\nobserved_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend\n\npartable = ParameterTable(\n    latent_vars = latent_vars, \n    observed_vars = observed_vars, \n    graph = graph)\n\ndata = example_data(\"political_democracy\")\n\nmodel = Sem(\n    specification = partable,\n    data = data\n)\n\nmodel_fit = sem_fit(model)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"After you fitted a model,","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"model_fit = sem_fit(model)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"you end up with an object of type SemFit.","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"You can get some more information about it by using the sem_summary function:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"sem_summary(model_fit)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"To compute fit measures, we use","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"fit_measures(model_fit)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"To inspect the parameter estimates, we can update a ParameterTable object and call sem_summary on it:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"update_estimate!(partable, model_fit)\n\nsem_summary(partable)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"We can also update the ParameterTable object with other information via update_partable!. For example, if we want to compare hessian-based and bootstrap-based standard errors, we may write","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"se_bs = se_bootstrap(model_fit; n_boot = 20)\nse_he = se_hessian(model_fit)\n\nupdate_partable!(partable, model_fit, se_he, :se_hessian)\nupdate_partable!(partable, model_fit, se_bs, :se_bootstrap)\n\nsem_summary(partable)","category":"page"},{"location":"tutorials/inspection/inspection/#Export-results","page":"Model inspection","title":"Export results","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"You may convert a ParameterTable to a DataFrame and use the DataFrames package for further analysis (or write to disk).","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"using DataFrames\n\nparameters_df = DataFrame(partable)","category":"page"},{"location":"tutorials/inspection/inspection/#Additional-functions","page":"Model inspection","title":"Additional functions","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"Additional functions that can be used to extract information from a SemFit object:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model inspection","title":"Model inspection","text":"– MISSING DOCSTRINGS –","category":"page"},{"location":"tutorials/fitting/fitting/#Model-fitting","page":"Model fitting","title":"Model fitting","text":"","category":"section"},{"location":"tutorials/fitting/fitting/","page":"Model fitting","title":"Model fitting","text":"As we saw in A first model, after you have build a model, you can fit it via","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model fitting","title":"Model fitting","text":"model_fit = sem_fit(model)\n\n# output\n\nFitted Structural Equation Model\n================================\n------------- Model ------------\nStructural Equation Model\n- Loss Functions\n   SemML\n- Fields\n   observed:  SemObsCommon\n   imply:     RAM\n   diff:      SemDiffOptim\n\n----- Optimization result ------\n * Status: success\n\n * Candidate solution\n    Final objective value:     2.120543e+01\n\n * Found with\n    Algorithm:     L-BFGS\n\n * Convergence measures\n    |x - x'|               = 3.81e-05 ≰ 1.5e-08\n    |x - x'|/|x'|          = 5.10e-06 ≰ 0.0e+00\n    |f(x) - f(x')|         = 1.05e-09 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 4.97e-11 ≤ 1.0e-10\n    |g(x)|                 = 7.31e-05 ≰ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    136\n    f(x) calls:    413\n    ∇f(x) calls:   413","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model fitting","title":"Model fitting","text":"You may optionally specify Starting values.","category":"page"},{"location":"developer/sem/#Custom-model-types","page":"Custom model types","title":"Custom model types","text":"","category":"section"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"The abstract supertype for all models is AbstractSem, which has two subtypes, AbstractSemSingle{O, I, L, D} and AbstractSemCollection. Currently, there are three subtypes of AbstractSemSingle: Sem, SemFiniteDiff and SemForwardDiff. All subtypes of AbstractSemSingle should have at least observed, imply, loss and diff fields, and share their types ({O, I, L, D}) with the parametric abstract supertype. For example, the SemFiniteDiff type is implemented as","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"struct SemFiniteDiff{O <: SemObs, I <: SemImply, L <: SemLoss, D <: SemDiff, G} <: AbstractSemSingle{O, I, L, D}\n    observed::O\n    imply::I\n    loss::L\n    diff::D\n    has_gradient::G\nend","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"Additionally, we need to define a method to compute at least the objective value, and if you want to use gradient based optimizers (which you most probably will), we need also to define a method to compute the gradient. For example, the respective fallback methods for all AbstractSemSingle models are defined as","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"function objective!(model::AbstractSemSingle, parameters)\n    objective!(imply(model), parameters, model)\n    return objective!(loss(model), parameters, model)\nend\n\nfunction gradient!(gradient, model::AbstractSemSingle, parameters)\n    fill!(gradient, zero(eltype(gradient)))\n    gradient!(imply(model), parameters, model)\n    gradient!(gradient, loss(model), parameters, model)\nend","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"Note that the gradient! method takes a pre-allocated array that should be filled with the gradient values.","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"Additionally, we can define constructors like the one in \"src/frontend/specification/Sem.jl\".","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"It is also possible to add new subtypes for AbstractSemCollection.","category":"page"},{"location":"tutorials/collection/multigroup/#Multigroup-models","page":"Multigroup models","title":"Multigroup models","text":"","category":"section"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"using StructuralEquationModels","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"As an example, we will fit the model from the lavaan tutorial with loadings constrained to equality across groups.","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"We first load the example data and split it between groups:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"dat = example_data(\"holzinger_swineford\")\n\ndat_g1 = dat[dat.school .== \"Pasteur\", :]\ndat_g2 = dat[dat.school .== \"Grant-White\", :]","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"dat = example_data(\"holzinger_swineford\")\n\ndat_g1 = dat[dat.school .== \"Pasteur\", :]\ndat_g2 = dat[dat.school .== \"Grant-White\", :]","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"We then specify our model via the graph interface:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"latent_vars = [:visual, :textual, :speed]\nobserved_vars = Symbol.(:x, 1:9)\n\ngraph = @StenoGraph begin\n    # measurement model\n    visual  → fixed(1.0, 1.0)*x1 + label(:λ₂, :λ₂)*x2 + label(:λ₃, :λ₃)*x3\n    textual → fixed(1.0, 1.0)*x4 + label(:λ₅, :λ₅)*x5 + label(:λ₆, :λ₆)*x6\n    speed   → fixed(1.0, 1.0)*x7 + label(:λ₈, :λ₈)*x8 + label(:λ₉, :λ₉)*x9\n    # variances and covariances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars)   ⇔ _(latent_vars)\nend","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"latent_vars = [:visual, :textual, :speed]\nobserved_vars = Symbol.(:x, 1:9)\n\ngraph = @StenoGraph begin\n    # measurement model\n    visual  → fixed(1, 1)*x1 + label(:λ₂, :λ₂)*x2 + label(:λ₃, :λ₃)*x3\n    textual → fixed(1, 1)*x4 + label(:λ₅, :λ₅)*x5 + label(:λ₆, :λ₆)*x6\n    speed   → fixed(1, 1)*x7 + label(:λ₈, :λ₈)*x8 + label(:λ₉, :λ₉)*x9\n    # variances and covariances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars)   ⇔ _(latent_vars)\nend","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"You can pass multiple arguments to fix() and label() for each group. Parameters with the same label (within and across groups) are constrained to be equal. To fix a parameter in one group, but estimate it freely in the other, you may write fix(NaN, 4.3).","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"You can then use the resulting graph to specify an EnsembleParameterTable","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"groups = [:Pasteur, :Grant_White]\n\npartable = EnsembleParameterTable(;\n    graph = graph, \n    observed_vars = observed_vars,\n    latent_vars = latent_vars,\n    groups = groups)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"The parameter table can be used to create a Dict of RAMMatrices with keys equal to the group names and parameter tables as values:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"specification = RAMMatrices(partable)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"That is, you can asses the group-specific RAMMatrices as specification[:group_name].","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"note: A different way to specify\nInstead of choosing the workflow \"Graph -> EnsembleParameterTable -> RAMMatrices\", you may also directly specify RAMMatrices for each group (for an example see this test).","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"The next step is to construct the model:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"model_g1 = Sem(\n    specification = specification[:Pasteur],\n    data = dat_g1\n)\n\nmodel_g2 = Sem(\n    specification = specification[:Grant_White],\n    data = dat_g2\n)\n\nmodel_ml_multigroup = SemEnsemble(model_g1, model_g2)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"We now fit the model and inspect the parameter estimates:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"solution = sem_fit(model_ml_multigroup)\nupdate_estimate!(partable, solution)\nsem_summary(partable)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"Other things you can query about your fitted model (fit measures, standard errors, etc.) are described in the section Model inspection and work the same way for multigroup models.","category":"page"},{"location":"#StructuralEquationModels.jl:-a-fast-and-flexible-SEM-framework","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"","category":"section"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"This is a package for Structural Equation Modeling. It is still in development. Models you can fit include","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"Linear SEM that can be specified in RAM notation\nML, GLS and FIML estimation\nRidge Regularization\nMultigroup SEM\nSums of arbitrary loss functions (everything the optimizer can handle)","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"We provide fast objective functions, gradients, and for some cases hessians as well as approximations thereof. As a user, you can easily define custom loss functions. For those, you can decide to provide analytical gradients or use finite difference approximation / automatic differentiation. You can choose to mix loss functions natively found in this package and those you provide. In such cases, you optimize over a sum of different objectives (e.g. ML + Ridge). This strategy also applies to gradients, where you may supply analytic gradients or opt for automatic differentiation or mixed analytical and automatic differentiation.","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"You may consider using this package if:","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"you want to extend SEM (e.g. add a new objective function)\nyou want to extend SEM, and your implementation needs to be fast\nyou want to fit the same model(s) to many datasets (bootstrapping, simulation studies)\nyou are planning a study and would like to do power simulations","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"For examples on how to use the package, see the Tutorials.","category":"page"},{"location":"#Installation","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"Installation","text":"","category":"section"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"You need to have julia installed and may want to additionally use an IDE of your choice (we like VS Code with the Julia extension).","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"To install the latest version of our package from GitHub, use the following commands:","category":"page"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"using Pkg\nPkg.add(url = \"https://github.com/StructuralEquationModels/StructuralEquationModels.jl\")","category":"page"},{"location":"#Citing-the-package","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"Citing the package","text":"","category":"section"},{"location":"","page":"StructuralEquationModels.jl: a fast and flexible SEM framework","title":"StructuralEquationModels.jl: a fast and flexible SEM framework","text":"To cite our package, see this page.","category":"page"},{"location":"internals/types/#Type-hierarchy","page":"types","title":"Type hierarchy","text":"","category":"section"},{"location":"internals/types/","page":"types","title":"types","text":"The type hierarchy is implemented in \"src/types.jl\".","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"AbstractSem: the most abstract type in our package","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"AbstractSemSingle{O, I, L, D} <: AbstractSem is an abstract parametric type that is a supertype of all single models\nSem: models that do not need automatic differentiation or finite difference approximation\nSemFiniteDiff: models whose gradients and/or hessians should be computed via finite difference approximation\nSemForwardDiff: models whose gradients and/or hessians should be computed via forward mode automatic differentiation\nAbstractSemCollection <: AbstractSem is an abstract supertype of all models that contain multiple AbstractSem submodels","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"Every AbstractSemSingle has to have SemObs, SemImply, SemLoss and SemDiff fields (and can have additional fields).","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"SemLoss is a container for multiple SemLossFunctions.","category":"page"},{"location":"developer/diff/#Custom-diff-types","page":"Custom diff types","title":"Custom diff types","text":"","category":"section"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"The diff part of a model connects it to the optimization backend. The first part of the implementation is very similar to loss functions, so we just show the implementation of SemDiffOptim here:","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"############################################################################\n### Types and Constructor\n############################################################################\n\nmutable struct SemDiffOptim{A, B} <: SemDiff\n    algorithm::A\n    options::B\nend\n\nSemDiffOptim(;algorithm = LBFGS(), options = Optim.Options(;f_tol = 1e-10, x_tol = 1.5e-8), kwargs...) = SemDiffOptim(algorithm, options)\n\n############################################################################\n### Recommended methods\n############################################################################\n\nupdate_observed(diff::SemDiffOptim, observed::SemObs; kwargs...) = diff\n\n############################################################################\n### additional methods\n############################################################################\n\nalgorithm(diff::SemDiffOptim) = diff.algorithm\noptions(diff::SemDiffOptim) = diff.options","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"Now comes a part that is a little bit more complicated: We need to write methods for sem_fit:","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"function sem_fit(model::AbstractSemSingle{O, I, L, D}; start_val = start_val, kwargs...) where {O, I, L, D <: SemDiffOptim}\n    \n    if !isa(start_val, Vector)\n        start_val = start_val(model; kwargs...)\n    end\n\n    optimization_result = ...\n\n    ...\n\n    return SemFit(minimum, minimizer, start_val, model, optimization_result)\nend","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"The method has to return a SemFit object that consists of the minimum of the objective at the solution, the minimizer (aka parameter estimates), the starting values, the model and the optimization result (which may be anything you desire for your specific backend).","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"If we want our type to also work with SemEnsemble models, we also have to provide a method for that:","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"function sem_fit(model::SemEnsemble{N, T , V, D, S}; start_val = start_val, kwargs...) where {N, T, V, D <: SemDiffOptim, S}\n\n    if !isa(start_val, Vector)\n        start_val = start_val(model; kwargs...)\n    end\n\n\n    optimization_result = ...\n\n    ...\n\n    return SemFit(minimum, minimizer, start_val, model, optimization_result)\n\nend","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"In addition, you might want to provide methods to access properties of your optimization result:","category":"page"},{"location":"developer/diff/","page":"Custom diff types","title":"Custom diff types","text":"optimizer(res::MyOptimizationResult) = ...\nn_iterations(res::MyOptimizationResult) = ...\nconvergence(res::MyOptimizationResult) = ...","category":"page"}]
}
